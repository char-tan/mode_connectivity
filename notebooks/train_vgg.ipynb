{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "0ox72K94Tk_f"
      },
      "id": "0ox72K94Tk_f"
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "EoU7-e4NcM4c",
        "outputId": "97f43214-6cb4-4454-eb2d-eea70d0afe63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EoU7-e4NcM4c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 27 16:20:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sets .py files to autoreload\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "i3iDyNgzZCBE"
      },
      "id": "i3iDyNgzZCBE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "999c2bc6",
      "metadata": {
        "id": "999c2bc6",
        "outputId": "d1e0b18c-8332-49fa-c2a4-92c806c70856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mode_connectivity'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (286/286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 286 (delta 157), reused 239 (delta 111), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (286/286), 6.78 MiB | 4.08 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n"
          ]
        }
      ],
      "source": [
        "# pull repo\n",
        "!git clone https://github.com/char-tan/mode_connectivity.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directory\n",
        "import os\n",
        "os.chdir('mode_connectivity')"
      ],
      "metadata": {
        "id": "FhffvuErVyVk"
      },
      "id": "FhffvuErVyVk",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkout branch\n",
        "!git checkout ct_dev"
      ],
      "metadata": {
        "id": "a4K8AFJTcYtt",
        "outputId": "e1c6f520-884e-4311-8f19-96ed2bfde52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "a4K8AFJTcYtt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'ct_dev' set up to track remote branch 'ct_dev' from 'origin'.\n",
            "Switched to a new branch 'ct_dev'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train models"
      ],
      "metadata": {
        "id": "60VHLDuSVpNe"
      },
      "id": "60VHLDuSVpNe"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fe1fb111",
      "metadata": {
        "id": "fe1fb111",
        "outputId": "fbd2dab8-032e-485d-dd0f-de9f48b6cdf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 2, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 3, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 4, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 5, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 6, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 7, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 8, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 9, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n",
            "Train Epoch: 10, Train Accuracy: (10%) \n",
            "Average loss: 2.3026, Accuracy: (10%)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from training_config import VGG_CIFAR10_DEFAULT\n",
        "from training import setup_train, train_model\n",
        "\n",
        "training_config = VGG_CIFAR10_DEFAULT\n",
        "training_config.epochs = 10\n",
        "training_config.seed = 7\n",
        "\n",
        "# train model a\n",
        "model_a = train_model(*setup_train(training_config), verbose = 1)\n",
        "torch.save(model_a.state_dict(), 'model_a.pt')                                "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "533dc1b5f6751e9c738350df3cd1b0ef5f569dd461507537431de13a6c09381e"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}